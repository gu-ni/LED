python -m torch.distributed.launch --nproc_per_node=1 --master_port=1234 --use_env run_train.py --diff_steps 1000 --lr 0.0001 --learning_steps 50000 --save_interval 10000 --seed 102 --noise_schedule sqrt --hidden_dim 128 --bsz 2048 --microbatch 128 --dataset qqp --data_dir datasets/CommonsenseConversation --seq_len 128 --schedule_sampler lossaware --notes test-qqp
